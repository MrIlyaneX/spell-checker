{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n",
        "\n",
        "- solving a problem of n-grams frequencies storing for a large corpus;\n",
        "- taking into account keyboard layout and associated misspellings;\n",
        "- efficiency improvement to make the solution faster;\n",
        "- ...\n",
        "\n",
        "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
        "\n",
        "##### IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unzip ./data/useful_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install tqdm rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "import rich  # for beatifull output formatting\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1020385it [00:02, 482455.45it/s]\n",
            "1044268it [00:05, 196437.16it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1130077, 3205806)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reading Ngram data\n",
        "def read_n_bigrams(path: str) -> tuple[dict[tuple[str] : int], set]:\n",
        "    data = defaultdict(int)\n",
        "    vocab = set()\n",
        "    with open(path, \"r\", encoding=\"latin1\") as file:\n",
        "        for line in tqdm(file):\n",
        "            line_ = line.lower().strip().split(\"\\t\")\n",
        "\n",
        "            # padding simulation\n",
        "            ln = len(line_) - 2\n",
        "            tpl = tuple([\"<s>\"] * ln + line_[1:] + [\"<s>\"] * ln)\n",
        "            for idx in range(len(tpl) - ln):\n",
        "                data[tpl[idx : len(line_) - 1 + idx]] = int(line_[0])\n",
        "\n",
        "            for elem in line_[1:]:\n",
        "                vocab.add(elem)\n",
        "    return data, vocab\n",
        "\n",
        "\n",
        "bigrams, vocab_bigrams = read_n_bigrams(\"./data/bigrams.txt\")\n",
        "fivegrams, vocab_fivegrams = read_n_bigrams(\"./data/fivegrams.txt\")\n",
        "\n",
        "vocab = vocab_bigrams & vocab_fivegrams\n",
        "len(bigrams), len(fivegrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class NGramModel:\n",
        "    def __init__(\n",
        "        self, ngram_count: dict[tuple[str], int], vocab: set, ngram_size: int = 2\n",
        "    ):\n",
        "        self.ngram_count = ngram_count\n",
        "        self.vocab = vocab\n",
        "        self.ngram_size = ngram_size\n",
        "\n",
        "        self.prev_grams = defaultdict(int)\n",
        "        for ngram, count in ngram_count.items():\n",
        "            self.prev_grams[ngram[:-1]] += count\n",
        "\n",
        "        self.probs = {}\n",
        "        for ngram, count in ngram_count.items():\n",
        "            self.probs[ngram] = (count + 1) / self.prev_grams[ngram[:-1]]\n",
        "\n",
        "    def evaluate_ngram(self, sequence, verbose: bool = False):\n",
        "        probability = 0\n",
        "        for i in range(len(sequence) - self.ngram_size + 1):\n",
        "            ngram = tuple(sequence[i : i + self.ngram_size])\n",
        "            probability += math.log(self.probs.get(ngram, 1e-10))\n",
        "\n",
        "            if verbose:\n",
        "                rich.print(ngram, math.log(self.probs.get(ngram, 1e-10)), probability)\n",
        "\n",
        "        return probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('female sport',\n",
              " 'male sport',\n",
              " 'these are',\n",
              " 'this is',\n",
              " 'organized sports',\n",
              " 'infected animals',\n",
              " 'enhance the quality of sleep')"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SpellCorrector:\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab: set,\n",
        "        ngrams: list[dict[tuple, int]],\n",
        "        max_dist: int = 20,\n",
        "        le: float = 0.5,\n",
        "        lm_1: float = 0.5,\n",
        "        lm_2: float = 0.5,\n",
        "    ):\n",
        "        self.vocab = vocab\n",
        "        self.lm = None\n",
        "        self.max_dist = max_dist\n",
        "\n",
        "        self.ngrams = ngrams\n",
        "        self.ngram_models = [\n",
        "            NGramModel(ngram_dict, self.vocab, ngram_size=ngram_size)\n",
        "            for ngram_dict, ngram_size in zip(self.ngrams, [2, 5])\n",
        "        ]\n",
        "\n",
        "        self.le = le\n",
        "        self.lm_1 = lm_1\n",
        "        self.lm_2 = lm_2\n",
        "\n",
        "    def dameru_levenshtein_distance(self, a: str, b: str) -> tuple[int, float]:\n",
        "        # source: https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance\n",
        "        m, n = len(a), len(b)\n",
        "        max_dist = m + n\n",
        "\n",
        "        alphabet = set(a) | set(b)\n",
        "        da = [0 for _ in range(len(alphabet) + 1)]\n",
        "        char2idx = {char: 0 for char in alphabet}\n",
        "\n",
        "        d = [[0 for i in range(n + 2)] for j in range(m + 2)]\n",
        "        d[0][0] = max_dist\n",
        "\n",
        "        for i in range(0, m + 1):\n",
        "            d[i + 1][0] = max_dist\n",
        "            d[i + 1][1] = i\n",
        "\n",
        "        for j in range(0, n + 1):\n",
        "            d[0][j + 1] = max_dist\n",
        "            d[1][j + 1] = j\n",
        "\n",
        "        a, b = \" \" + a, \" \" + b\n",
        "        for i in range(1, m + 1):\n",
        "            db = 0\n",
        "            min_cost = float(\"inf\")\n",
        "            for j in range(1, n + 1):\n",
        "                k = da[char2idx[b[j]]]\n",
        "                l = db\n",
        "                if a[i] == b[j]:\n",
        "                    cost = 0\n",
        "                    db = j\n",
        "                else:\n",
        "                    cost = 2\n",
        "                substitution = d[i][j] + cost\n",
        "                insertion = d[i + 1][j] + 1\n",
        "                deletion = d[i][j + 1] + 1\n",
        "                d[i + 1][j + 1] = min(substitution, insertion, deletion)\n",
        "\n",
        "                # trying to not doing extra calculations\n",
        "                if i > 1 and j > 1 and a[i - 1] == b[j - 2] and a[i - 2] == b[j - 1]:\n",
        "                    d[i + 1][j + 1] = min(d[i + 1][j + 1], d[k][l] + cost)\n",
        "\n",
        "                min_cost = min(d[i + 1][j + 1], min_cost)\n",
        "\n",
        "            if min_cost >= self.max_dist:\n",
        "                return self.max_dist + 1\n",
        "\n",
        "            da[char2idx[a[i]]] = i\n",
        "\n",
        "        return d[m + 1][n + 1]\n",
        "\n",
        "    def __generate_candidates(self, pretendant: str, top_k: int = 20):\n",
        "        candidates = []\n",
        "        n = len(pretendant)\n",
        "        pret_set = set(pretendant)\n",
        "        for word in self.vocab:\n",
        "            if abs(len(word) - n) > self.max_dist:\n",
        "                continue\n",
        "            if len(pret_set.intersection(set(word))) < (len(pret_set) / 2):\n",
        "                continue\n",
        "\n",
        "            dist = self.dameru_levenshtein_distance(pretendant, word)\n",
        "            if dist <= self.max_dist:\n",
        "                candidates.append((word, dist))\n",
        "\n",
        "        return sorted(candidates, key=lambda x: x[1])[:top_k]\n",
        "\n",
        "    def __evaluate_candidates(\n",
        "        self,\n",
        "        sentence: list[str],\n",
        "        candidates: tuple[list[str], int],\n",
        "        candidate_idx: int,\n",
        "        verbose: bool,\n",
        "    ) -> str:\n",
        "        best = None\n",
        "        best_score = -float(\"inf\")\n",
        "\n",
        "        for candidate, dist in candidates:\n",
        "            scores = {}\n",
        "            for model in self.ngram_models:\n",
        "                start_idx, end_idx = (\n",
        "                    max(candidate_idx - model.ngram_size + 1, 0),\n",
        "                    min(candidate_idx + model.ngram_size, len(sentence)),\n",
        "                )\n",
        "\n",
        "                sent_copy = sentence.copy()\n",
        "                sent_copy[candidate_idx] = candidate\n",
        "\n",
        "                left_slice = sent_copy[start_idx : candidate_idx + 1]\n",
        "                right_slice = sent_copy[candidate_idx:end_idx]\n",
        "                left = len(sent_copy[start_idx : candidate_idx + 1])\n",
        "\n",
        "                if left != model.ngram_size:\n",
        "                    left_slice = [\"<s>\"] * (model.ngram_size - left) + sent_copy[\n",
        "                        start_idx : candidate_idx + 1\n",
        "                    ]\n",
        "\n",
        "                sent = left_slice + right_slice[1:]\n",
        "\n",
        "                scores[model.ngram_size] = model.evaluate_ngram(\n",
        "                    sequence=sent, verbose=verbose\n",
        "                )\n",
        "\n",
        "            combined_score = (\n",
        "                -self.le * dist + self.lm_1 * scores[2] + self.lm_2 * scores[5]\n",
        "            )\n",
        "            if verbose:\n",
        "                rich.print(\n",
        "                    f\"{candidate}\\t{combined_score=}\\t\", dist, scores[2], scores[5]\n",
        "                )\n",
        "\n",
        "            if combined_score > best_score:\n",
        "                best_score = combined_score\n",
        "                best = candidate\n",
        "\n",
        "        return best\n",
        "\n",
        "    def spell_checker(\n",
        "        self, text: str, top_k: int = 10_000, verbose: list[bool] = [False, False]\n",
        "    ) -> str:\n",
        "        words = re.findall(r\"\\w+\", text.lower())\n",
        "        corrected_sentence = []\n",
        "\n",
        "        for idx, word in enumerate(words):\n",
        "            corrected_word = word\n",
        "            if word not in self.vocab:\n",
        "                candidates = self.__generate_candidates(pretendant=word, top_k=top_k)\n",
        "\n",
        "                best_one = self.__evaluate_candidates(\n",
        "                    sentence=words,\n",
        "                    candidates=candidates,\n",
        "                    candidate_idx=idx,\n",
        "                    verbose=verbose[0],\n",
        "                )\n",
        "                corrected_word = best_one\n",
        "            elif verbose[1]:\n",
        "                candidates = self.__generate_candidates(pretendant=word, top_k=top_k)\n",
        "                ecand = self.__evaluate_candidates(\n",
        "                    sentence=words,\n",
        "                    candidates=candidates,\n",
        "                    candidate_idx=idx,\n",
        "                    verbose=verbose[1],\n",
        "                )\n",
        "                rich.print(\"non-changed:\\n\", ecand, \"\\n\\n\")\n",
        "            words[idx] = corrected_word\n",
        "            corrected_sentence.append(corrected_word)\n",
        "        return \" \".join(corrected_sentence)\n",
        "\n",
        "\n",
        "top_k = 10000\n",
        "verbose = [False, False]\n",
        "spell_corrector = SpellCorrector(vocab=vocab, ngrams=[bigrams, fivegrams], max_dist=10)\n",
        "(\n",
        "    spell_corrector.spell_checker(\"fml sport\", verbose=verbose, top_k=top_k),\n",
        "    spell_corrector.spell_checker(\"mle sport\", verbose=verbose, top_k=top_k),\n",
        "    # 'these are / this is' are seen by model\n",
        "    spell_corrector.spell_checker(\"these aris\", verbose=verbose, top_k=top_k),\n",
        "    spell_corrector.spell_checker(\"this aris\", verbose=verbose, top_k=top_k),\n",
        "    spell_corrector.spell_checker(\n",
        "        \"dking sports\", verbose=verbose, top_k=top_k\n",
        "    ),  # see explanations: corpora does not have such pairs\n",
        "    spell_corrector.spell_checker(\"dking animals\", verbose=verbose, top_k=top_k),\n",
        "    spell_corrector.spell_checker(\n",
        "        \"encnhanceded the quaility of slewp\", verbose=verbose, top_k=top_k\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "### My approach\n",
        "\n",
        "I used following idea: \n",
        "\n",
        "- per each single word we can find it's _corrections_. By _corrections_ I mean finding the words into wich the word could be changed (based on data of unigrams I collect). By doing so, I will retrieve some top-k words that could be 'derived' by correcting the word: most probably the _true_ word will be in the top-k ones, even if the initial word is correct (but I assume that the wrong words a those that not included in _vocab_ that model was buid on).\n",
        "\n",
        "- Using NGram Language Model, pick one word from top-k ones, chosen in prev. step (with some number of surrounding words) and compute the probabilities that model gives for the chosen word to be in the sentence. Pick the best word based on highest probability.\n",
        "\n",
        "Potentially these actions could be vectorized, so some speed-up could be gain.\n",
        "\n",
        "### What I need to implement\n",
        "\n",
        "- Collect unigrams for single word spell corrector\n",
        "- Collect NGrams for Ngram LM\n",
        "- Unigram corrector: \n",
        "    - Distance to see 'similarity' words (it could be named differently)\n",
        "- NGram LM:\n",
        "    - Train the model on the data\n",
        "\n",
        "- Evaluator to evaluate the solution:\n",
        "    - 'Correctness' of spellcheking\n",
        "    - 'Time' used for the algorithm\n",
        "\n",
        "### Difficulties\n",
        "\n",
        "The 'top-k' approach with the general distance computation for pairs of words (even with possible improvements) work quite slowly. I see the only way to fix it: use the other way of singe-word-correction\n",
        "\n",
        "My implementation does not handle _wrong word by meaning_, since I check for words to correct initially based on grammar / syntax, then I pick the most suitable word using NLM predictions  \n",
        "\n",
        "### What and Why I have used\n",
        "\n",
        "Word change distance: \n",
        "\n",
        "As I know, three main algorithms used: Levenshtein, Damerau–Levenshtein and Optimal String Allignment (OSA).\n",
        "Other algortithms, like Hamming distance, etc. seem to be used in some specifiec scenarios, not the general spelling correction.\n",
        "\n",
        "My idea was to use an algorithm, that is capable of fixing 3+ mistaken letter, therefore I used Damerau–Levenshtein (but it's quite computation expensive)\n",
        "\n",
        "The Damerau–Levenshtein:\n",
        "\n",
        "- Insert / Delete / Swap operations, as in Levenshtein distance or in OSA\n",
        "- Transpositions (or order swap of characters)\n",
        "    - Adjacent transposition: adjacent characters in word swapped positions - typo fix (as in OSA)\n",
        "    - Overlapping transposition: handle cases with keyboard misstyping - only the Damerau–Levenshtein supports it\n",
        "- The algorithm is about _O(mn)_, but it could be speeded up using tree-based structures to about _O(m log n)_ comlexity (not implemented)\n",
        "\n",
        "\n",
        "The Damerau–Levenshtein distance is optimised by early stopping by max edit distance:\n",
        "\n",
        "- In some way, the Norvig approach is faster thanks to 2-edit based words, since the number of comparisons \\ operations is in magnitude lower, but with the cases of higher changes / transposes Norvig does no work, while distance calculation works\n",
        "\n",
        "My solution is quite slow compared to the Norvig on larger sentences (moreover, I use in some sense 1-2-3-4-5 gram models implicinty by creating paddings), but my optimisations slightly speeded-up the algorithm\n",
        "\n",
        "The _top_k_ parameter increase does not signigicanly slows the model's performance, this increases the overall generalization of the model's corrections (sometimes it's more like an word changer)  \n",
        "\n",
        "Algorithm is capable of correcting multiple words in sentence\n",
        "\n",
        "##### Ngram Language Models\n",
        "\n",
        "For Ngram Language Model I used rough estimating of probabilities, since building matrix of ngram, as we usually made is too memory-consuming for such large vocablurary size: the ordinaty solution to create matrix is generally impossible for n>3, as more than 18GB RAM needed (tested this to compare RAM usage of approaches). Even bigram table uses near 8GB RAM with these data, while dicrionary-based 2 and 5 gram models need less than 800MB of RAM.\n",
        "\n",
        "My implementation uses 2 and 5 gram language models, with \"Model Interpolation\" approach in combining the results of estimations. \n",
        "\n",
        "\n",
        "#### Data\n",
        "\n",
        "I do not clean data in sense, that stopwords (that usually removed) could be used to correct. Moreover, I assumed to  lowercase all words, since small number of original words is capitalized (but mostly vocab I use is lowercased, this might be some issue) and therefore I will get high number of 'unk tokens' for predictions\n",
        "\n",
        "##### I used the bigrams, fivegrams dataset from moodle\n",
        "\n",
        "- The 'dking' example does from description not work, since corpora does not have these ones\n",
        "- In the brief test case near the SpellChecker was implemented, I showed some pair-cases that are working, since similar data was in corpora\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results\n",
        "\n",
        "For evaluation I simply use NLTK's dataset, wich is already structured text and it is easy to download.\n",
        "\n",
        "Unfortunatelly, I could not 'beat' the Norvig's performance in the test set, but my model seems to be more robust, since the accuracy drop is not that significant, as Norvig's. \n",
        "\n",
        "I used fixed seed - compared to some random seed, this is hard seed, since usually Norvig's scores higher than 0.7, and my model lower by ~0.2 points every time \n",
        "\n",
        "'By eye approximation' - with good enought educational vocablurary, some context - based addition appearence of words. For cases with high errors probability (0.6 anf greater) my model has slighly higher accuracy if using with _top_k_ less than 100 (increased robustness, but overall with smaller _top_k_ the average performance drops)\n",
        "\n",
        "--- Noise Probability: 0.01 ---\n",
        "\n",
        "Norvig:\n",
        " - Word Acc: 0.58\n",
        " - Sent Acc: 0.58\n",
        "\n",
        "My Model:\n",
        " - Word Acc: 0.26\n",
        " - Sent Acc: 0.26\n",
        "\n",
        "--- Noise Probability: 0.1 ---\n",
        "\n",
        "Norvig:\n",
        " - Word Acc: 0.38\n",
        " - Sent Acc: 0.38\n",
        "\n",
        "My Model:\n",
        " - Word Acc: 0.2\n",
        " - Sent Acc: 0.2\n",
        "\n",
        "--- Noise Probability: 0.4 ---\n",
        "\n",
        "Norvig:\n",
        " - Word Acc: 0.08\n",
        " - Sent Acc: 0.08\n",
        "\n",
        "My Model:\n",
        " - Word Acc: 0.06\n",
        " - Sent Acc: 0.06\n",
        "\n",
        " --- Noise Probability: 0.8 ---\n",
        "\n",
        "Norvig:\n",
        " - Word Acc: 0.04\n",
        " - Sent Acc: 0.04\n",
        " \n",
        " My Model:\n",
        " - Word Acc: 0.02\n",
        " - Sent Acc: 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This part populates the file from ngram files\n",
        "# Quite ineffective implementation + no lowering\n",
        "def populate_with_text(ngram_sets: dict[tuple, int]) -> list[str]:\n",
        "    text = defaultdict(int)\n",
        "    for ngram_set in ngram_sets:\n",
        "        for key, item in ngram_set.items():\n",
        "            for word in key:\n",
        "                if word != \"<s>\":\n",
        "                    text[word] += item\n",
        "    return text\n",
        "\n",
        "\n",
        "big_text = populate_with_text(ngram_sets=[bigrams, fivegrams])\n",
        "# End of populating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Norvig's solution\n",
        "# it's just copy-paste from web-page for fair comparison with my solution + added capital letters\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def words(text):\n",
        "    return re.findall(r\"\\w+\", text.lower())\n",
        "\n",
        "\n",
        "WORDS = big_text  # Counter(words(open(\"big.txt\").read()))\n",
        "\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "\n",
        "def correction(word):\n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "\n",
        "def candidates(word):\n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
        "\n",
        "\n",
        "def known(words):\n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes = [L + R[1:] for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "    inserts = [L + c + R for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "\n",
        "def edits2(word):\n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /Users/ilia/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "\n",
        "nltk.download(\"brown\")\n",
        "random.seed(124)\n",
        "\n",
        "\n",
        "def add_noise(word: str, noise_prob: float = 0.1):\n",
        "    if random.random() > noise_prob or len(word) < 2:\n",
        "        return word\n",
        "\n",
        "    ops = [\"d\", \"i\", \"s\", \"t\"]\n",
        "    op = random.choice(ops)\n",
        "    idx = random.randint(0, len(word) - 1)\n",
        "\n",
        "    if op == \"d\":\n",
        "        return word[:idx] + word[idx + 1 :]\n",
        "    elif op == \"i\":\n",
        "        return word[:idx] + random.choice(r\"a-z\") + word[idx:]\n",
        "    elif op == \"s\":\n",
        "        return word[:idx] + random.choice(r\"a-z\") + word[idx + 1 :]\n",
        "    elif op == \"t\" and idx < len(word) - 1:\n",
        "        return word[:idx] + word[idx + 1] + word[idx] + word[idx + 2 :]\n",
        "    return word\n",
        "\n",
        "\n",
        "def word_accuracy(original: list[str], corrected: list[str]):\n",
        "    correct = sum(o == c for o, c in zip(original, corrected))\n",
        "    total = len(original)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def sentence_accuracy(original_sents: list[str], corrected_sents: list[str]):\n",
        "    correct_sents = sum(o == c for o, c in zip(original_sents, corrected_sents))\n",
        "    return correct_sents / len(original_sents)\n",
        "\n",
        "\n",
        "def evaluate_models(model: SpellCorrector, noise_probs=[0.01, 0.1, 0.4, 0.8]):\n",
        "    sentences = brown.sents(categories=\"news\")[:50]\n",
        "\n",
        "    for p in noise_probs:\n",
        "        print(f\"\\n--- Noise Probability: {p} ---\")\n",
        "        dataset = [\n",
        "            (\" \".join(sent), \" \".join([add_noise(word, p) for word in sent]))\n",
        "            for sent in sentences\n",
        "        ]\n",
        "        original_sents = [\n",
        "            \" \".join(re.findall(r\"\\w+\", orig.lower())) for orig, _ in dataset\n",
        "        ]\n",
        "        noisy_sents = [\n",
        "            \" \".join(re.findall(r\"\\w+\", noisy.lower())) for _, noisy in dataset\n",
        "        ]\n",
        "\n",
        "        norvig_corrected = [\n",
        "            \" \".join(correction(w) for w in re.findall(r\"\\w+\", sent))\n",
        "            for sent in noisy_sents\n",
        "        ]\n",
        "\n",
        "        spell_cheker_corrected = [model.spell_checker(sent) for sent in noisy_sents]\n",
        "\n",
        "        print(\"Norvig:\")\n",
        "        print(\" - Word Acc:\", word_accuracy(original_sents, norvig_corrected))\n",
        "        print(\" - Sent Acc:\", sentence_accuracy(original_sents, norvig_corrected))\n",
        "\n",
        "        print(\"My Model:\")\n",
        "        print(\" - Word Acc:\", word_accuracy(original_sents, spell_cheker_corrected))\n",
        "        print(\" - Sent Acc:\", sentence_accuracy(original_sents, spell_cheker_corrected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Noise Probability: 0.01 ---\n",
            "Norvig:\n",
            " - Word Acc: 0.58\n",
            " - Sent Acc: 0.58\n",
            "My Model:\n",
            " - Word Acc: 0.26\n",
            " - Sent Acc: 0.26\n",
            "\n",
            "--- Noise Probability: 0.1 ---\n",
            "Norvig:\n",
            " - Word Acc: 0.38\n",
            " - Sent Acc: 0.38\n",
            "My Model:\n",
            " - Word Acc: 0.2\n",
            " - Sent Acc: 0.2\n",
            "\n",
            "--- Noise Probability: 0.4 ---\n",
            "Norvig:\n",
            " - Word Acc: 0.08\n",
            " - Sent Acc: 0.08\n",
            "My Model:\n",
            " - Word Acc: 0.06\n",
            " - Sent Acc: 0.06\n",
            "\n",
            "--- Noise Probability: 0.8 ---\n",
            "Norvig:\n",
            " - Word Acc: 0.04\n",
            " - Sent Acc: 0.04\n",
            "My Model:\n",
            " - Word Acc: 0.02\n",
            " - Sent Acc: 0.02\n"
          ]
        }
      ],
      "source": [
        "evaluate_models(spell_corrector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Useful resources (also included in the archive in moodle):\n",
        "\n",
        "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
        "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
